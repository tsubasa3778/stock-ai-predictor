# scripts/train_lstm.py
"""
=========================
ğŸ“˜ ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç›®çš„ã¨ä»•çµ„ã¿ï¼ˆè§£èª¬ï¼‰
=========================

ğŸ§  ã€ç›®çš„ã€‘
- ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã€ŒLSTM + Attention ãƒ¢ãƒ‡ãƒ«ã€ã‚’ç”¨ã„ã¦ã€
  å„ä¼æ¥­ã®æ ªä¾¡ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¾ã™ã€‚

ğŸ“ˆ ã€ã‚„ã£ã¦ã„ã‚‹ã“ã¨ã€‘
1. å„ä¼æ¥­ã”ã¨ã«ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼š
   - éå»10å–¶æ¥­æ—¥åˆ†ã®ç‰¹å¾´é‡ï¼ˆãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ï¼‹æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ï¼‰
   - ãã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€Œæœªæ¥5æ—¥å¾Œãƒ»10æ—¥å¾Œãƒ»30æ—¥å¾Œã€ã®æ ªä¾¡ï¼ˆæ­£è§£ï¼‰

2. ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã™ã‚‹ç‰¹å¾´é‡ï¼š
   - SMAï¼ˆå˜ç´”ç§»å‹•å¹³å‡ï¼‰5æ—¥/15æ—¥
   - EMAï¼ˆæŒ‡æ•°ç§»å‹•å¹³å‡ï¼‰5æ—¥
   - RSIï¼ˆç›¸å¯¾åŠ›æŒ‡æ•°ï¼‰
   - ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ï¼ˆãã®æ—¥ã®å¹³å‡Ã—è¨˜äº‹æ•°ï¼‰

3. LSTMãƒ¢ãƒ‡ãƒ«ã¯ã€Œéå»10æ—¥åˆ†ã®ç‰¹å¾´é‡ã€ã‹ã‚‰ã€Œæœªæ¥â—¯å–¶æ¥­æ—¥å¾Œã®æ ªä¾¡ã€ã‚’äºˆæ¸¬

4. ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã¯ RMSEï¼ˆäºˆæ¸¬ã¨æ­£è§£ã®èª¤å·®ï¼‰ã§è©•ä¾¡

ğŸ–¼ ã€å‡ºåŠ›ã•ã‚Œã‚‹ã‚°ãƒ©ãƒ•ã€‘
- é’ã„ç·šï¼šå®Ÿéš›ã®æ ªä¾¡ï¼ˆæ­£è§£ãƒ‡ãƒ¼ã‚¿ï¼‰
- ã‚ªãƒ¬ãƒ³ã‚¸ã®ç‚¹ç·šï¼šLSTMãŒäºˆæ¸¬ã—ãŸæ ªä¾¡

ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼š
         æ™‚ç³»åˆ— â†’
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   å®Ÿéš›ï¼šé’ã„ç·š             â”‚
    â”‚         ï¼ï¼¼     ï¼ï¼¼      â”‚
    â”‚        ï¼   ï¼¼ï¼    ï¼¼__   â”‚
    â”‚                            â”‚
    â”‚   äºˆæ¸¬ï¼šã‚ªãƒ¬ãƒ³ã‚¸ç‚¹ç·š       â”‚
    â”‚       â€¦â†’â€¦â€¦â€¦â†’â€¦â€¦â€¦â†’â€¦        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸš€ ã€çµæœã€‘
- å„ä¼æ¥­ã”ã¨ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã™ï¼š
  - ä¾‹ï¼šdata/lstm_predictions/ãƒˆãƒ¨ã‚¿_future10.png

"""

import os
import sys
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
from matplotlib import rcParams
import pandas.tseries.offsets as offsets

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆsymbols_config.py ç­‰ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ï¼‰
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from symbols_config import stock_list

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆWindowsã®å ´åˆ "Meiryo" ãªã©ï¼‰
rcParams['font.family'] = 'Meiryo'

# ====== 1. LSTM + Attention ãƒ¢ãƒ‡ãƒ«å®šç¾© ======
class StockLSTMAttention(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super(StockLSTMAttention, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.attention = nn.Linear(hidden_size, 1)
        self.fc = nn.Linear(hidden_size, 1)
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        attn_scores = self.attention(lstm_out)
        attn_weights = torch.softmax(attn_scores, dim=1)
        context_vector = torch.sum(lstm_out * attn_weights, dim=1)
        output = self.fc(context_vector)
        return output

# ====== 2. Dataset ã‚¯ãƒ©ã‚¹ ======
class StockDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32)
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# ====== 3. ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ä½œæˆé–¢æ•°ï¼ˆæœªæ¥nå–¶æ¥­æ—¥å¾Œã®äºˆæ¸¬ï¼‰ ======
def create_sequences(data, target, seq_len, future):
    xs, ys = [], []
    for i in range(len(data) - seq_len - future + 1):
        xs.append(data[i:i+seq_len])
        ys.append(target[i+seq_len+future-1])
    return np.array(xs), np.array(ys)

# ====== 4. æœªæ¥äºˆæ¸¬ç”¨ã®é€æ¬¡äºˆæ¸¬é–¢æ•° ======
def predict_future(model, last_sequence, n_steps, scaler_y, device):
    current_seq = last_sequence.copy()
    predictions = []
    for _ in range(n_steps):
        input_tensor = torch.tensor(current_seq, dtype=torch.float32).unsqueeze(0).to(device)
        pred = model(input_tensor).cpu().detach().numpy()[0][0]
        predictions.append(pred)
        # ã“ã“ã§ã¯ Close å€¤ã®ã¿ã‚’äºˆæ¸¬ã™ã‚‹å‰æ
        new_row = np.array([pred])
        # ã‚‚ã—ç‰¹å¾´é‡ãŒ1ã¤ã®ã¿ãªã‚‰ new_row ã®ã‚µã‚¤ã‚ºã¯ (1,) ã¨ã™ã‚‹ãŒ current_seq ã¯ (seq_len, features)
        # ä»Šå› features = 5 â†’ æ ªä¾¡ã¯1ã¤ãªã®ã§ã€ä»–ã®4ç‰¹å¾´é‡ã¯æœ€æ–°å€¤ã‚’ãã®ã¾ã¾ç¶­æŒ
        # ã“ã“ã§ã¯ç°¡ä¾¿ã®ãŸã‚ã€new_row ã‚’ [pred, current_seq[-1,1:]] ã¨ã—ã¦æ¨ªçµåˆ
        # â€» å®Ÿéš›ã¯å„ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®å‹•å‘ã‚’äºˆæ¸¬ã™ã‚‹ã®ã¯é›£ã—ã„ãŸã‚ã€Close ã®ã¿äºˆæ¸¬ã—ã€ä»–ã¯æœ€æ–°å€¤ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚
        new_row = np.hstack(([pred], current_seq[-1, 1:]))
        current_seq = np.vstack((current_seq[1:], new_row))
    predictions = np.array(predictions).reshape(-1, 1)
    predictions_inv = scaler_y.inverse_transform(predictions)
    return predictions_inv.flatten()

# ====== 5. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ======
SEQ_LEN = 10                        # éå»ãƒ‡ãƒ¼ã‚¿ã®æ—¥æ•°ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼‰
FUTURE_STEPS = [5, 10, 30]          # æœªæ¥äºˆæ¸¬å¯¾è±¡ï¼š5, 10, 30å–¶æ¥­æ—¥å¾Œ
EPOCHS = 50
BATCH_SIZE = 32
LR = 0.001
HIDDEN_SIZE = 64
NUM_LAYERS = 2
SAVE_DIR = "data/lstm_predictions"
os.makedirs(SAVE_DIR, exist_ok=True)

# ====== 6. CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ======
# ã€Œdata/merged_sentiment_stock.csvã€ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»æ ªä¾¡ãªã©ãŒçµ±åˆæ¸ˆã¿ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚
df = pd.read_csv("data/merged_sentiment_stock.csv", parse_dates=["date"])
# æ—¥ä»˜ã‚’æ™‚åˆ»ãªã—ã®Dateå‹ã«å¤‰æ›
df["date"] = pd.to_datetime(df["date"]).dt.normalize().dt.date
df = df.dropna(subset=["company"])

# ====== 7. å„ä¼æ¥­ã”ã¨ã®å­¦ç¿’ãƒ»æœªæ¥äºˆæ¸¬ ======
companies = df["company"].unique()
print("å¯¾è±¡ä¼æ¥­:", companies)

for company in companies:
    print(f"\nğŸ”„ {company} ã®å­¦ç¿’é–‹å§‹...")
    comp_df = df[df["company"] == company].sort_values("date").copy()
    if comp_df.empty:
        print(f"âš ï¸ {company}: ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")
        continue

    # --- æ ªä¾¡ã‹ã‚‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®å†è¨ˆç®— ---
    comp_df["Close"] = pd.to_numeric(comp_df["Close"], errors="coerce")
    comp_df["SMA_5"] = comp_df["Close"].rolling(window=5, min_periods=1).mean()
    comp_df["SMA_15"] = comp_df["Close"].rolling(window=15, min_periods=1).mean()
    comp_df["EMA_5"] = comp_df["Close"].ewm(span=5, adjust=False).mean()
    delta = comp_df["Close"].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(window=14, min_periods=1).mean()
    avg_loss = loss.rolling(window=14, min_periods=1).mean()
    comp_df["RSI"] = 100 - (100 / (1 + avg_gain / avg_loss))
    
    # --- åŒæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æ„Ÿæƒ…ã‚¹ã‚³ã‚¢çµ±åˆ ---
    # ï¼ˆã€Œscoreã€åˆ—ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã€‚ weighted_score = score_mean * è¨˜äº‹æ•°ï¼‰
    grouped = comp_df.groupby("date").agg({
        "Close": "mean",
        "SMA_5": "mean",
        "SMA_15": "mean",
        "EMA_5": "mean",
        "RSI": "mean",
        "score": ["mean", "count"]
    }).reset_index()
    grouped.columns = ["date", "Close", "SMA_5", "SMA_15", "EMA_5", "RSI", "score_mean", "score_count"]
    grouped["weighted_score"] = grouped["score_mean"] * grouped["score_count"]

    # æ—¥ä»˜ã‚’ datetime å‹ã«å¤‰æ›ã—ã¦ãŠã
    grouped["date"] = pd.to_datetime(grouped["date"])
    # æ¬ æå‡¦ç†ï¼šå‰æ–¹åŸ‹ã‚
    grouped[["Close", "SMA_5", "SMA_15", "EMA_5", "RSI", "weighted_score"]] = grouped[["Close", "SMA_5", "SMA_15", "EMA_5", "RSI", "weighted_score"]].ffill()
    
    # å–¶æ¥­æ—¥ãƒ™ãƒ¼ã‚¹ã®å†æ§‹ç¯‰
    start_date = grouped["date"].min()
    end_date = grouped["date"].max()
    business_dates = pd.date_range(start=start_date, end=end_date, freq="B")
    bdays_df = pd.DataFrame({"date": business_dates})
    merged_df = pd.merge(bdays_df, grouped, on="date", how="left")
    merged_df[["Close", "SMA_5", "SMA_15", "EMA_5", "RSI", "weighted_score"]] = \
    merged_df[["Close", "SMA_5", "SMA_15", "EMA_5", "RSI", "weighted_score"]].ffill().bfill()

    # æ—¥ä»˜ã‚’ object å‹ã§ã¯ãªã date å‹ã«å¤‰æ›
    merged_df["date"] = merged_df["date"].dt.date

    features = ["SMA_5", "SMA_15", "EMA_5", "RSI", "weighted_score"]
    if merged_df[features + ["Close"]].isnull().any().any() or len(merged_df) < SEQ_LEN + max(FUTURE_STEPS):
        print(f"âš ï¸ {company}: æ¬ æã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ä¸è¶³ â†’ ã‚¹ã‚­ãƒƒãƒ—")
        continue

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    x_scaler = MinMaxScaler()
    y_scaler = MinMaxScaler()
    X_scaled = x_scaler.fit_transform(merged_df[features])
    y_scaled = y_scaler.fit_transform(merged_df[["Close"]])

    # --- å„æœªæ¥äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å­¦ç¿’ã¨è©•ä¾¡ ---
    for future in FUTURE_STEPS:
        print(f"â–¶ï¸ {future}å–¶æ¥­æ—¥å¾Œäºˆæ¸¬")
        X_seq, y_seq = create_sequences(X_scaled, y_scaled, SEQ_LEN, future)
        if len(X_seq) == 0:
            print(f"âš ï¸ {company}: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ{future}æ—¥å¾Œï¼‰ â†’ ã‚¹ã‚­ãƒƒãƒ—")
            continue

        total_seq = len(X_seq)
        train_size = int(total_seq * 0.8)
        X_train, X_test = X_seq[:train_size], X_seq[train_size:]
        y_train, y_test = y_seq[:train_size], y_seq[train_size:]
        if len(X_train) == 0 or len(X_test) == 0:
            print(f"âš ï¸ {company}: å­¦ç¿’ã¾ãŸã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ{future}æ—¥å¾Œï¼‰ â†’ ã‚¹ã‚­ãƒƒãƒ—")
            continue

        train_ds = StockDataset(X_train, y_train)
        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = StockLSTMAttention(input_size=X_train.shape[2], hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS).to(device)
        loss_fn = nn.MSELoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=LR)

        for epoch in range(EPOCHS):
            model.train()
            total_loss = 0
            for xb, yb in train_loader:
                xb, yb = xb.to(device), yb.to(device)
                optimizer.zero_grad()
                loss = loss_fn(model(xb), yb)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
            if (epoch + 1) % 10 == 0 or epoch == 0:
                print(f"{company} - Epoch {epoch+1}/{EPOCHS} (future={future}), Loss: {total_loss/len(train_loader):.4f}")

        model.eval()
        with torch.no_grad():
            y_pred = model(torch.tensor(X_test, dtype=torch.float32).to(device)).cpu().numpy()
        y_test_inv = y_scaler.inverse_transform(y_test.reshape(-1, 1))
        y_pred_inv = y_scaler.inverse_transform(y_pred)
        rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))
        print(f"{company} ã® {future}å–¶æ¥­æ—¥å¾Œ RMSE: {rmse:.2f}")

        # ãƒ†ã‚¹ãƒˆã‚°ãƒ©ãƒ•ï¼šãƒ†ã‚¹ãƒˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾å¿œã™ã‚‹å–¶æ¥­æ—¥ã®æ—¥ä»˜ã‚’å–å¾—
        test_dates = []
        for i in range(len(X_test)):
            idx = train_size + i + SEQ_LEN + future - 1
            if idx < len(merged_df):
                test_dates.append(merged_df["date"].iloc[idx])
            else:
                test_dates.append(merged_df["date"].iloc[-1])
        
        plt.figure(figsize=(10, 6))
        plt.plot(test_dates, y_test_inv, label="Actual", color="blue")
        plt.plot(test_dates, y_pred_inv, label=f"Predicted ({future}å–¶æ¥­æ—¥å¾Œ)", color="orange", linestyle="--")
        plt.title(f"{company} æ ªä¾¡äºˆæ¸¬ ({future}å–¶æ¥­æ—¥å¾Œ) - RMSE: {rmse:.2f}")
        plt.xlabel("æ—¥ä»˜")
        plt.ylabel("æ ªä¾¡")
        plt.legend()
        plt.grid(True)
        plt.xticks(rotation=45)
        test_save_path = os.path.join(SAVE_DIR, f"{company}_future{future}.png")
        plt.savefig(test_save_path, bbox_inches="tight")
        plt.close()
        print(f"âœ… {company} â†’ {future}å–¶æ¥­æ—¥å¾Œãƒ†ã‚¹ãƒˆäºˆæ¸¬ä¿å­˜: {test_save_path}")

        # --- å®Œå…¨ãªæœªæ¥äºˆæ¸¬ (æœ€æ–°ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰æœªçŸ¥ã®æœªæ¥å€¤ã®ã¿) ---
        last_sequence = X_scaled[-SEQ_LEN:]
        future_pred = predict_future(model, last_sequence, future, y_scaler, device)
        last_date = pd.to_datetime(merged_df["date"].iloc[-1])
        future_dates = pd.bdate_range(last_date + pd.Timedelta(days=1), periods=future)
        
        plt.figure(figsize=(10, 6))
        plt.plot(future_dates, future_pred, label=f"Future Predicted ({future}å–¶æ¥­æ—¥å¾Œ)", color="green", linestyle="--", marker="o")
        plt.title(f"{company} æœªæ¥äºˆæ¸¬ ({future}å–¶æ¥­æ—¥å¾Œ)")
        plt.xlabel("æ—¥ä»˜")
        plt.ylabel("æ ªä¾¡")
        plt.legend()
        plt.grid(True)
        plt.xticks(rotation=45)
        future_save_path = os.path.join(SAVE_DIR, f"{company}_future{future}_future.png")
        plt.savefig(future_save_path, bbox_inches="tight")
        plt.close()
        print(f"âœ… {company} æœªæ¥äºˆæ¸¬ä¿å­˜: {future_save_path}")
