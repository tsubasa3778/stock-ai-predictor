import streamlit as st
import pandas as pd
import os
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib
import time
import altair as alt
from scrape_news import run_scraper

# â”€â”€â”€ ãƒšãƒ¼ã‚¸è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="æ ªä¾¡äºˆæ¸¬AIã‚¢ãƒ—ãƒª", layout="wide")
matplotlib.rcParams['font.family'] = 'Meiryo'

# â”€â”€â”€ ãƒ¢ãƒã‚¤ãƒ«ç”¨CSSï¼†ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
@media only screen and (max-width: 600px) {
    .main { padding: 1rem; }
    h1 { font-size: 1.5rem; }
    .block-container { padding: 0.5rem 1rem; }
}
/* ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« */
.streamlit-expanderContent pre {
    overflow-x: auto;
}
</style>
""", unsafe_allow_html=True)
st.title("è‡ªåˆ†å°‚ç”¨ æ ªä¾¡äºˆæ¸¬ AI ã‚¢ãƒ—ãƒª ğŸ“ˆ")

# â”€â”€â”€ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œå‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
script_dir = os.path.dirname(__file__)
project_root = os.path.abspath(os.path.join(script_dir, ".."))
project_data = os.path.join(project_root, "data")
app_data = os.path.join(script_dir, "data")
DATA_DIR = project_data if os.path.exists(project_data) else app_data

# â”€â”€â”€ ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_path(*candidates):
    for p in candidates:
        if p and os.path.exists(p): return p
    return None

# â”€â”€â”€ ä¼æ¥­ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from symbols_config import stock_list
    companies = [s["name"] for s in stock_list]
except:
    companies = []

# â”€â”€â”€ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "scraping" not in st.session_state: st.session_state.scraping = False
if "stop_scraping" not in st.session_state: st.session_state.stop_scraping = False

# â”€â”€â”€ ã‚µã‚¤ãƒ‰ãƒ¡ãƒ‹ãƒ¥ãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸é¸æŠ", [
    "ãƒ‹ãƒ¥ãƒ¼ã‚¹æ„Ÿæƒ…åˆ†æ",
    "LSTMæ ªä¾¡äºˆæ¸¬",
    "ã‚³ãƒ¼ãƒ‰é–²è¦§",
    "æ„Ÿæƒ… vs æ ªä¾¡å¤‰åŒ–"
])

# ====================
# ãƒ‹ãƒ¥ãƒ¼ã‚¹æ„Ÿæƒ…åˆ†æ ãƒšãƒ¼ã‚¸
# ====================
if page == "ãƒ‹ãƒ¥ãƒ¼ã‚¹æ„Ÿæƒ…åˆ†æ":
    st.header("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹æ„Ÿæƒ…åˆ†æãƒ‡ãƒ¼ã‚¿")

    # CSV æ¤œå‡º
    path1 = os.path.join(DATA_DIR, "news_sentiment.csv")
    path2 = os.path.join(DATA_DIR, "news_sentiment", "news_sentiment.csv")
    csv_path = path1 if os.path.exists(path1) else (path2 if os.path.exists(path2) else None)

    if csv_path:
        df_all = pd.read_csv(csv_path, parse_dates=["date"])
        df_all["year_month"] = df_all["date"].dt.to_period("M").astype(str)

        sent_companies = sorted(df_all["company"].unique())
        selected_company = st.selectbox("ä¼æ¥­ã‚’é¸æŠã—ã¦ãã ã•ã„", sent_companies)
        df = df_all[df_all["company"] == selected_company]

        st.subheader("ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ä¸€è¦§")
        st.dataframe(df.tail(500), use_container_width=True)

        months = sorted(df["year_month"].unique(), reverse=True)
        selected_month = st.selectbox("æœˆã‚’é¸æŠã—ã¦ãã ã•ã„", months)
        df_month = df[df["year_month"] == selected_month]

        # æ—¥åˆ¥å¹³å‡ã‚¹ã‚³ã‚¢ + 7æ—¥ç§»å‹•å¹³å‡
        daily = df_month.set_index("date")["score"] \
                        .resample("D").mean().fillna(0).to_frame() \
                        .rename(columns={"score": "score"})
        daily["ma7"] = daily["score"].rolling(7, center=True).mean() \
                               .fillna(method="ffill").fillna(method="bfill")
        daily = daily.reset_index()

        st.subheader(f"{selected_month} ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢æ—¥åˆ¥æ¨ç§»")
        base = alt.Chart(daily).encode(x=alt.X("date:T", title="æ—¥ä»˜"))
        points = base.mark_circle(size=40).encode(
            y=alt.Y("score:Q", title="ã‚¹ã‚³ã‚¢"),
            color=alt.condition("datum.score >= datum.ma7", alt.value("steelblue"), alt.value("orange")),
            tooltip=[
                alt.Tooltip(field="date", type="temporal", title="æ—¥ä»˜"),
                alt.Tooltip(field="score", type="quantitative", format=".3f", title="ã‚¹ã‚³ã‚¢"),
                alt.Tooltip(field="ma7", type="quantitative", format=".3f", title="7æ—¥ç§»å‹•å¹³å‡")
            ]
        )
        line = base.mark_line(size=3).encode(
            y=alt.Y("ma7:Q", title="7æ—¥ç§»å‹•å¹³å‡"),
            tooltip=[
                alt.Tooltip(field="date", type="temporal", title="æ—¥ä»˜"),
                alt.Tooltip(field="ma7", type="quantitative", format=".3f", title="7æ—¥ç§»å‹•å¹³å‡")
            ]
        )
        st.altair_chart(alt.layer(points, line).properties(height=300), use_container_width=True)

        # æœˆåˆ¥è¨˜äº‹ä»¶æ•°
        monthly = df.set_index("date")["title"].resample("M").count().reset_index().rename(columns={"title":"ä»¶æ•°"})
        st.subheader("æœˆåˆ¥è¨˜äº‹ä»¶æ•°ï¼ˆéå»1å¹´ï¼‰")
        bar = alt.Chart(monthly).mark_bar().encode(
            x=alt.X("date:T", timeUnit="yearmonth", title="å¹´æœˆ"),
            y=alt.Y("ä»¶æ•°:Q", title="ä»¶æ•°"),
            tooltip=[
                alt.Tooltip(field="date", type="temporal", timeUnit="yearmonth", title="å¹´æœˆ"),
                alt.Tooltip(field="ä»¶æ•°", type="quantitative", title="ä»¶æ•°")
            ]
        ).properties(height=200)
        st.altair_chart(bar, use_container_width=True)
    else:
        st.info("ã¾ã ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸‹ã®ãƒœã‚¿ãƒ³ã§åé›†ã—ã¦ãã ã•ã„ã€‚")

    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    if not st.session_state.scraping and st.button("ğŸ“¥ ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ã™ã‚‹"):
        st.session_state.scraping = True
        st.session_state.stop_scraping = False
    if st.session_state.scraping:
        pb = st.progress(0); status = st.empty()
        if st.button("ğŸ›‘ ã‚­ãƒ£ãƒ³ã‚»ãƒ«"): st.session_state.stop_scraping = True
        start = time.time()
        def cb(r):
            if st.session_state.stop_scraping: raise RuntimeError("ğŸ›‘ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
            elapsed = time.time() - start
            eta = (elapsed/r)*(1-r) if r>0 else 0
            m,s = divmod(int(eta),60)
            status.text(f"é€²æ—ï¼š{r*100:.1f}% | æ®‹ã‚Šï¼š{m}åˆ†{s}ç§’")
            pb.progress(min(r,1.0))
        try:
            run_scraper(progress_callback=cb, should_stop=lambda: st.session_state.stop_scraping)
            st.success("âœ… å®Œäº†ï¼")
        except RuntimeError as e:
            st.warning(str(e))
        st.session_state.scraping = False
        st.session_state.stop_scraping = False

# ====================
# LSTMæ ªä¾¡äºˆæ¸¬ ãƒšãƒ¼ã‚¸
# ====================
elif page == "LSTMæ ªä¾¡äºˆæ¸¬":
    st.header("ğŸ“Š æ ªä¾¡äºˆæ¸¬çµæœ")
    company = st.selectbox("ä¼æ¥­ã‚’é¸æŠã—ã¦ãã ã•ã„", companies)
    future_path = os.path.join(DATA_DIR, "lstm_predictions", f"{company}_future10.png")

    if os.path.exists(future_path):
        st.image(future_path, caption=f"{company} - 10å–¶æ¥­æ—¥å¾Œäºˆæ¸¬", use_container_width=True)
    else:
        st.warning(f"{company} ã®äºˆæ¸¬ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")


# ====================
# ã‚³ãƒ¼ãƒ‰é–²è¦§ ãƒšãƒ¼ã‚¸
# ====================
elif page == "ã‚³ãƒ¼ãƒ‰é–²è¦§":
    st.header("ğŸ“„ ã‚¢ãƒ—ãƒªã‚³ãƒ¼ãƒ‰ä¸€è¦§")
    base_dir = os.path.abspath(os.path.dirname(__file__))
    files = ["scrape_news.py","merge_sentiment_stock.py","train_lstm.py","app.py","symbols_config.py"]
    for fname in files:
        file_path = os.path.join(base_dir, fname)
        if os.path.exists(file_path):
            st.subheader(fname)
            code = open(file_path, encoding="utf-8").read()
            with st.expander("ã‚³ãƒ¼ãƒ‰ã‚’è¡¨ç¤º"): st.code(code, language="python")
            st.download_button(label=f"{fname} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=code, file_name=fname, mime="text/x-python")
        else:
            st.warning(f"{fname} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# ====================
# æ„Ÿæƒ… vs æ ªä¾¡å¤‰åŒ– ãƒšãƒ¼ã‚¸
# ====================
elif page == "æ„Ÿæƒ… vs æ ªä¾¡å¤‰åŒ–":
    st.header("ğŸ’¬ æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ vs æ ªä¾¡å¤‰åŒ–")
    sel = st.selectbox("ä¼æ¥­ã‚’é¸æŠã—ã¦ãã ã•ã„", companies)
    vs_img = find_path(
        os.path.join(project_data, "sentiment_vs_stock", f"{sel}.png"),
        os.path.join(app_data,     "sentiment_vs_stock", f"{sel}.png")
    )
    if vs_img:
        st.image(Image.open(vs_img), caption="æ„Ÿæƒ…ã¨æ ªä¾¡ã®æ¯”è¼ƒ", use_container_width=True)
    else:
        st.warning(f"{sel} ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

st.markdown("---")
st.markdown("ğŸ“Œ **äºˆæ¸¬èª¤å·®ï¼ˆRMSEï¼‰**ï¼šäºˆæ¸¬ã¨å®Ÿéš›ã®æ ªä¾¡ã®ã‚ºãƒ¬ã‚’ç¤ºã™æŒ‡æ¨™ã€‚å°ã•ã„ã»ã©é«˜ç²¾åº¦ã€‚")

import subprocess
import threading
import time

# --- Cloudflare Tunnel èµ·å‹•é–¢æ•° ---
def start_tunnel():
    time.sleep(5)  # Streamlitã‚µãƒ¼ãƒãƒ¼èµ·å‹•å¾…ã¡
    try:
        result = subprocess.run(
            ["cloudflared", "tunnel", "--url", "http://localhost:8501", "--no-autoupdate"],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True
        )
        print("âœ… Cloudflare Tunnel çµ‚äº†")
        print(result.stdout)
    except Exception as e:
        print("âŒ Tunnel èµ·å‹•ã‚¨ãƒ©ãƒ¼:", e)

# --- åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§ãƒˆãƒ³ãƒãƒ«èµ·å‹•ï¼ˆStreamlitã¨ä¸¦è¡Œå®Ÿè¡Œï¼‰ ---
threading.Thread(target=start_tunnel, daemon=True).start()
